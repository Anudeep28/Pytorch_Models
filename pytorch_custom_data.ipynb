{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Custom Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Note: this notebook requires torch >= 1.10.0\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Data\n",
    "- Our dataset is a subset of the Food101 dataset.\n",
    "- Food101 starts with 101 different categories of food and 1000 images per class ( 750 training, 250 each testing)\n",
    "- Our dataset starts with 3 classes of food and only 10% of the images (~75% training, 25 testing each)\n",
    "- Why do this?\n",
    "- When starting with ML project, it's important to try things on small scale and then increase the scale when necessary.\n",
    "- The whole point is to speed up how fast you can experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to the data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# if the image folder doesn't exist , download it and perpare it\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory already exists ..... skipping download\")\n",
    "else:\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the data\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\")as f:\n",
    "    #### Always copy the raw file from the github\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading.....\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# unzip the zip file downloaded\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unziping the dataset.......\")\n",
    "    zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Becoming one with the data ( data preparation and data exploration )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "    \"\"\"Walks through dir path returning its contents.\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training and testing paths **\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Visualizing and images\n",
    "\n",
    "Lets write some code to:\n",
    "1. Get all of the image paths\n",
    "2. Pick a random image path using python's `random.choice()`\n",
    "3. Get the image class name using `Pathlib.Path.parent.stem`\n",
    "4. Since we are working with images, open the image using PIL library\n",
    "5. We will show th image and print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# set Seed\n",
    "random.seed(42)\n",
    "\n",
    "# 1.  get all the image paths\n",
    "image_path_lists = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# 2. Random image path and plot it\n",
    "random_image_path = random.choice(image_path_lists)\n",
    "#print(random_image_path)\n",
    "\n",
    "# 3. Get the image class from the path name ( the image class is the name of the directory where the image is stored)\n",
    "image_class = random_image_path.parent.stem\n",
    "#print(image_class)\n",
    "\n",
    "# 4. Open image \n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. print Metadata\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image Height: {img.height}\")\n",
    "print(f\"Image Width: {img.width}\")\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to visulaize the image with mmatplotlib library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn the image into an array\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Plot the image with matplotlib\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image Shape: {img_as_array.shape} -> [Height, Width, Colour Channel]\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transforming Data\n",
    "Before we can use our data with pytorch:\n",
    "1. Turn your target data into tensors ( in our case, numerical representation of our images).\n",
    "2. Turn it into a `torch.utils.data.Dataset`  sunsequently turned into `torch.utils.data.DataLoader`\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Transforming data with torchvision.transforms\n",
    "Transforms help you get your images ready to be used with a model/perform data augmentation Link: https://pytorch.org/vision/stable/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a transform for an image\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize our images to 64*64\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # Turn the images into a torch.Tensor\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_path, transform, n=3, seed=42):\n",
    "    \"\"\"\n",
    "    Selects random images from a path of images and loads/Transforms\n",
    "    them then plots the original vs the transformed version.\n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        random.seed(42)\n",
    "    random_image_path = random.sample(image_path, k=n)\n",
    "    for image_path in random_image_path:\n",
    "        with Image.open(image_path) as f:    \n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "            ax[0].imshow(f) # type: ignore\n",
    "            ax[0].set_title(f\"Original\\nSize: {f.size}\") # type: ignore\n",
    "            ax[0].axis(False) # type: ignore\n",
    "\n",
    "            # TRansform and plot target image\n",
    "            transformed_image = transform(f).permute(1,2,0) # changing the order from (C,H,W) -> (H,W,C)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "plot_transformed_images(image_path=image_path_lists,\n",
    "                        transform=data_transform,\n",
    "                        n=3,\n",
    "                        seed=42\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Option 1. Loading image data using `ImageFolder`\n",
    "We can load image classification data using `torchvision.datasets.ImageFolder` : https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the ImageFolder to create datasets(s)\n",
    "# Pre-build datasets function developed ny Pytorch to load the data in certain structure format\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir, # type: ignore\n",
    "                                  transform=data_transform, # A transform for the data (Custom ones)\n",
    "                                  target_transform=None, # A transform for the target\n",
    "                                  )\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                                 transform=data_transform\n",
    "                                 )\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as dict()\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of our datasets\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index on the train data Dataset to get a single image and label\n",
    "img, label = train_data[0]\n",
    "print(f\"Image Tensor:\\n {img}\")\n",
    "print(f\"Image Shape: {img.shape}\")\n",
    "print(f\"Image Datatype: {img.dtype}\")\n",
    "print(f\"Image Label: {class_names[label]}\")\n",
    "print(f\"Label Dataype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrage the order of dimensions\n",
    "img_permute = img.permute(1,2,0)\n",
    "\n",
    "# print out different shapes\n",
    "print(f\"Original Shape: {img.shape} -> [Color_channels,Height,Width]\")\n",
    "print(f\"Image PErmuted shape: {img_permute.shape} -> [Height, Width, color_channels]\")\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img_permute)\n",
    "plt.axis(\"off\")\n",
    "plt.title(class_names[label], fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Turn datasets into `Dataloader`\n",
    "A `Dataloader` is going to help turn our datasets into iterables and we can customize the `batch_size` so our model can see batch size at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn traina and test into dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 1\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=1,#os.cpu_count(),\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             num_workers=1,#os.cpu_count(),\n",
    "                             shuffle=True)\n",
    "\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "# Batrch size will be one, you can change the batch size if you like\n",
    "print(f\"Image Shape: {img.shape} -> [batch_size, colour_channels, height, width]\")\n",
    "print(f\"Label Shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Option 2: Loading Image data with Custom `Dataset` instead using Pytorch nuild in functionality.\n",
    "1. Want to be able to load images from file\n",
    "2. Want to be able to get class names from the dataset\n",
    "3. Want to be able to get classes as dictionary from the dataset\n",
    "\n",
    "Pros:\n",
    "* Can create a `Dataset` out of almost anything\n",
    "* Not limited to pytorch pre-built `dataset` functions\n",
    "\n",
    "Cons:\n",
    "* Even though you could create `Datasets` out of almost anything, it doesnt mean it wil work.....\n",
    "* Using a `Custom Dataset` often results in us writing more code, which could be prone to more errors or peformance issues.\n",
    "\n",
    "All customs datasets in pytorch, often subclass - https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of torchvision.datasets.ImageFolder()\n",
    "train_data.classes, train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Creating a helper function to get class names\n",
    "We want a function to:\n",
    "1. Get the class names using `os.scandir` to traverse a target directory (ideally the directory is in standard image classification format)\n",
    "2. Raise an error if te class names aren't found (if this happens, there might be something wrong with directort structure)\n",
    "3. Turn the class names into a dict and  alist and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Path for target directory\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "target_directory = train_dir\n",
    "print(f\"Target Dir: {target_directory}\")\n",
    "\n",
    "# Get the class names from the target directory\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
    "class_names_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.scandir(target_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the Above Steps into a executable function\n",
    "def find_classes(directory: str) -> Tuple[list[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the Class folder names in a target directory\"\"\"\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in list(os.scandir(directory)) if entry.is_dir())\n",
    "\n",
    "    # 2. Raise an error if class names not to be found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.... Please Check!!!\")\n",
    "    \n",
    "    # 3. Create a dictionary of index labels ( comapre prefer numbers rather than strings as labels )\n",
    "    class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
    "\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create a custom `Dataset` to replicate `ImageFolder` functionality\n",
    "* To create our Own dataset, we ewant to:\n",
    "1. subclass `torch.utils.data.Dataset`\n",
    "2. Init our subclass with a target dicrectory ( the directory we would like to get data from ) as well as a transform if we would like to transform our data\n",
    "3. Create several attributes:\n",
    "* paths - paths of out images\n",
    "* transform - the transform we would like to perform\n",
    "* classes - a list to get the target classes\n",
    "* class_to_idx - a dict of the target classes mapped to integer labels\n",
    "4. create a function to `load_images()`, this function will open images\n",
    "5. Overwrite `__len()__` method to return the length of our dataset\n",
    "Overwrite the `__getitem()__` method to returhn a given sample when passed an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom dataset class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "    # 2. Initialize our custom dataset\n",
    "    def __init__(self, \n",
    "                targ_dir: str,\n",
    "               transform=None):\n",
    "        # 3. Create class attributes\n",
    "        # Get all the images paths here\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        # Create classes adn class_to_idx\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Create a function to load images\n",
    "    def load_images(self, index: int) -> Image.Image:\n",
    "        \"\"\"Opens an image via path and returns it\"\"\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "    \n",
    "    # 5. Overwrite __len()__\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the total number of samples\"\"\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Overwrite __getitem()__ method to return a sample\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"Returns one sample of data, and the data label (X,y)\"\"\"\n",
    "        img = self.load_images(index)\n",
    "        class_name = self.paths[index].parent.name # Expects path in format: data_folder/class_name/image.jpg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # Return data and lable index\n",
    "        else:\n",
    "            return img, class_idx # type: ignore # return untransformed image and label index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our custom dataset function\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our custom ImageFolderCustom\n",
    "train_data_custom = ImageFolderCustom(\n",
    "    targ_dir=train_dir,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "test_data_custom = ImageFolderCustom(\n",
    "    targ_dir=test_dir,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "train_data_custom, test_data_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original one\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(train_data_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data), len(test_data_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equality between original imageFolder Dataset and ImageFolderCustomDataset\n",
    "print(train_data_custom.classes==train_data.classes)\n",
    "print(test_data_custom.classes==test_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Create a function to display random images\n",
    "\n",
    "1. Taken in `Dataset` and number of other paramerters such as class names and how many images to visualize.\n",
    "2. To prevent the display getting out of hand, lets cap the number of images to see at 10.\n",
    "3. Set the random seed for reproducibility.\n",
    "4. Get a lsit of random sample indexes from the target dataset.\n",
    "5. Setup a matlplotlib plot.\n",
    "6. Loop through the random sample images and plot them with matpotlib.\n",
    "7. Make sure the dimensions of our images line up with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a function to take in a dataset\n",
    "import random\n",
    "def display_random_images(dataset: torch.utils.data.Dataset, # type: ignore\n",
    "                          classes: List[str]=None, # type: ignore\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None): # type: ignore\n",
    "    # 2. Adjust if n is very high\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"For Display, Purpose, n shouldn't be larger than 10, setting to 10 and removing the display\")\n",
    "    \n",
    "    # 3. Set the seed\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 4. Get the random sample indexes\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # 5. Setup Matplotlib plot\n",
    "    plt.figure(figsize=(16,8))\n",
    "\n",
    "    # 6. Loop through random indexes and plot them with matplotlib\n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        # 7. Adjust tensor dimensions for plotting\n",
    "        targ_image_adjust = targ_image.permute(1,2,0) # Changing [C,H,W] -> [H,W,C]\n",
    "\n",
    "        # Plot the adjusted Image\n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"Class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nShape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random images fromt the ImageFolder created in ImageFolder\n",
    "display_random_images(dataset=train_data,\n",
    "                      n=5,\n",
    "                      classes = class_names,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random images from the ImageFolderCustom Dataset\n",
    "display_random_images(dataset=train_data_custom,\n",
    "                      n=5,\n",
    "                      classes=class_names,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Turn custom Loaded images into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "NUMBER_WORKERS = 0  # os.cpu_count()\n",
    "train_dataloader_custom = DataLoader(dataset=train_data_custom,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     num_workers=NUMBER_WORKERS,\n",
    "                                     shuffle=True)\n",
    "\n",
    "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    num_workers=NUMBER_WORKERS,\n",
    "                                    shuffle=False)\n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Image adn label from custom Dataloader\n",
    "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
    "\n",
    "# Print out the shapes\n",
    "img_custom.shape, label_custom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Other forms of transforms ( Data Augmentation )\n",
    "* Data augmentation is the process of artificially addign diversity to your trainign data.\n",
    "* In this case of image data, this may mean applying various image transformation to the trainig images.\n",
    "* Lets take a look at one aprticular type of data augmentation used to train PyTorch vision models to state of the art levels....\n",
    "* this practise enables model to generalize more on the unseeen data\n",
    "* blog post: https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/\n",
    "* Augmentations : https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at Trivial Augment -> https://pytorch.org/vision/main/generated/torchvision.transforms.TrivialAugmentWide.html#torchvision.transforms.TrivialAugmentWide\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the image paths\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "image_path_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random transformed images\n",
    "plot_transformed_images(image_path=image_path_list,\n",
    "                        transform=train_transform,\n",
    "                        n=4,\n",
    "                        seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Model 0: TinyVGG without the data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Creating Transform and loading data for Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple transform\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and transform data\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data_simple = datasets.ImageFolder(root=train_dir,\n",
    "                                         transform=simple_transform)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
    "                                        transform=simple_transform)\n",
    "\n",
    "# 2, Turn the datasets into DataLoaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup batch size and the number of works\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 1#os.cpu_count()\n",
    "\n",
    "# CCreate DataLaoders\n",
    "train_dataloader_simple = DataLoader(dataset=train_data_simple,\n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Create TinyVGG model class\n",
    "\n",
    "reading article : https://horace.io/brrr_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Model Architecture copying TinyVGG from cnn Explainer\"\"\"\n",
    "    def __init__(self, input_shape: int,\n",
    "                hidden_units: int,\n",
    "                output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default value of stride is same as kernel size\n",
    "\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*13*13,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.conv_block_1(x)\n",
    "        # #print(x.shape)\n",
    "        # x = self.conv_block_2(x)\n",
    "        # #print(x.shape)\n",
    "        # x = self.classifier_layer(x)\n",
    "        #return x\n",
    "        return self.classifier_layer(self.conv_block_2(self.conv_block_1(x))) # benefits of using this type of syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3,\n",
    "                  hidden_units=10,\n",
    "                  output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Try a forward pass on a single image data ( to test te model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single image batch\n",
    "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a forward pass\n",
    "model_0(image_batch.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To get the output shapes of the layers created int he model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined functions to calcluate the output shapes from every layer\n",
    "import math\n",
    "\n",
    "def num2tuple(num):\n",
    "    return num if isinstance(num, tuple) else (num, num)\n",
    "\n",
    "def conv2d_output_shape(h_w, hiddle_shape: int=10, batch_size: int=32, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "    h_w, kernel_size, stride, pad, dilation = num2tuple(h_w), \\\n",
    "        num2tuple(kernel_size), num2tuple(stride), num2tuple(pad), num2tuple(dilation)\n",
    "    pad = num2tuple(pad[0]), num2tuple(pad[1])\n",
    "    \n",
    "    h = math.floor((h_w[0] + sum(pad[0]) - dilation[0]*(kernel_size[0]-1) - 1) / stride[0] + 1)\n",
    "    w = math.floor((h_w[1] + sum(pad[1]) - dilation[1]*(kernel_size[1]-1) - 1) / stride[1] + 1)\n",
    "    \n",
    "    return batch_size,hiddle_shape,h, w\n",
    "\n",
    "def convtransp2d_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1, out_pad=0):\n",
    "    h_w, kernel_size, stride, pad, dilation, out_pad = num2tuple(h_w), \\\n",
    "        num2tuple(kernel_size), num2tuple(stride), num2tuple(pad), num2tuple(dilation), num2tuple(out_pad)\n",
    "    pad = num2tuple(pad[0]), num2tuple(pad[1])\n",
    "    \n",
    "    h = (h_w[0] - 1)*stride[0] - sum(pad[0]) + dilation[0]*(kernel_size[0]-1) + out_pad[0] + 1\n",
    "    w = (h_w[1] - 1)*stride[1] - sum(pad[1]) + dilation[1]*(kernel_size[1]-1) + out_pad[1] + 1\n",
    "    \n",
    "    return h, w\n",
    "\n",
    "def conv2d_get_padding(h_w_in, h_w_out, kernel_size=1, stride=1, dilation=1):\n",
    "    h_w_in, h_w_out, kernel_size, stride, dilation = num2tuple(h_w_in), num2tuple(h_w_out), \\\n",
    "        num2tuple(kernel_size), num2tuple(stride), num2tuple(dilation)\n",
    "    \n",
    "    p_h = ((h_w_out[0] - 1)*stride[0] - h_w_in[0] + dilation[0]*(kernel_size[0]-1) + 1)\n",
    "    p_w = ((h_w_out[1] - 1)*stride[1] - h_w_in[1] + dilation[1]*(kernel_size[1]-1) + 1)\n",
    "    \n",
    "    return (math.floor(p_h/2), math.ceil(p_h/2)), (math.floor(p_w/2), math.ceil(p_w/2))\n",
    "\n",
    "def convtransp2d_get_padding(h_w_in, h_w_out, kernel_size=1, stride=1, dilation=1, out_pad=0):\n",
    "    h_w_in, h_w_out, kernel_size, stride, dilation, out_pad = num2tuple(h_w_in), num2tuple(h_w_out), \\\n",
    "        num2tuple(kernel_size), num2tuple(stride), num2tuple(dilation), num2tuple(out_pad)\n",
    "        \n",
    "    p_h = -(h_w_out[0] - 1 - out_pad[0] - dialation[0]*(kernel_size[0]-1) - (h_w[0] - 1)*stride[0]) / 2\n",
    "    p_w = -(h_w_out[1] - 1 - out_pad[1] - dialation[1]*(kernel_size[1]-1) - (h_w[1] - 1)*stride[1]) / 2\n",
    "    \n",
    "    return (math.floor(p_h/2), math.ceil(p_h/2)), (math.floor(p_w/2), math.ceil(p_w/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Use `torchinfo` to get an idea of the shapes going through out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another way to get the informatin of our model ####\n",
    "from torchinfo import summary\n",
    "#model = TinyVGG(input_shape=3,hidden_units=10,output_shape=10)\n",
    "summary(model_0,input_size=(BATCH_SIZE,3,64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 Crete a train dna test step loop functions\n",
    "\n",
    "* `train_step()`: takes in a mdoel and dataloader and trains the model on the dataloader\n",
    "* `test_step()`: takes in a model and the dataloader and evaluates the model on the dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_step funcxtion\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device=device):\n",
    "    # Put the model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # loop through dataloader data batches\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # send data tot eh target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. forward Pass\n",
    "        y_pred = model(X) # output is in logits\n",
    "\n",
    "        # 2. Calculate the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Soptimizer to zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optmizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate the accuracy metric\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class==y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust mertrics to get the average metrics per batch\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test step\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device=device):\n",
    "    # Put the model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # setup test loss and test accuract metrics\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Trurn on inference mode\n",
    "    with torch.inference_mode():\n",
    "        # loop througfh thte dataloader batches\n",
    "        for batch, (X,y) in enumerate(dataloader):\n",
    "            # convert to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate the loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels==y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "    # Adjust the metrics to get the average of the accuracy per batch\n",
    "    test_loss /= len(dataloader)\n",
    "    test_acc /= len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 Creating a `train()` function to combine `train_step()` and `test_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Create a train function that takes in various model parameters + optimizer + dataloader +++\n",
    "def train_loop(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5,\n",
    "          device=device\n",
    "          ):\n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\":[],\n",
    "               \"train_acc\":[],\n",
    "               \"test_loss\":[],\n",
    "               \"test_acc\":[]\n",
    "               }\n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "        \n",
    "        # 4. Print out  whats happening\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss: .4f} | Train acc: {train_acc: .4f} | Test loss: {test_loss: .4f} | Test acc: {test_acc: .4f}\")\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7 Train and evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "# set the random seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# set the number of epochs\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "# recreate an instance of tinyVGG\n",
    "model_0 = TinyVGG(input_shape=3, # Number of color channels of our target images\n",
    "                  hidden_units=10,\n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "\n",
    "# Setup a loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "# start the timer \n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# train the model_0\n",
    "model_0_results = train_loop(model=model_0, # type: ignore\n",
    "                             train_dataloader=train_dataloader_simple,\n",
    "                             test_dataloader=test_dataloader_simple,\n",
    "                             optimizer=optimizer,\n",
    "                             loss_fn=loss_fn,\n",
    "                             epochs=NUM_EPOCHS,\n",
    "                             device=device)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total trainig timing for {NUM_EPOCHS} : {end_time - start_time: .3f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8 plot the loss curve of model 0\n",
    "* A **loss curve** is a way to track your models progress over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model_0_results keys\n",
    "model_0_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def plot_loss_curves(results: Dict[str,list[float]]):\n",
    "    \"\"\"Plot training curves of a reuslt dictionary\"\"\"\n",
    "    # get the loss values of the results dicitonary\n",
    "    loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    # Get the accuracy values of the results duitionary\n",
    "    accuracy = results[\"train_acc\"]\n",
    "    test_accuracy = results[\"test_acc\"]\n",
    "\n",
    "    # Figure out how many epochs were there\n",
    "    epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "    # setup the plott\n",
    "    plt.figure(figsize=(15,7))\n",
    "\n",
    "    # plot the loss\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, loss, label=\"train_loss\")\n",
    "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # plot the accuracy\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
    "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(results=model_0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 What should an ideal loss curve look like?\n",
    "* Interpreting loss curves: https://developers.google.com/machine-learning/testing-debugging/metrics/interpretic\n",
    "* pre-trained models: https://pytorch.org/vision/0.8/models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Model 1: TinyVGG with Data augmentation\n",
    "* Now lets try another modeling experiment this time using the same model as before with some data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Create transform with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training transform with TrivialAugment\n",
    "train_transform_trivial = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform_trivial = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Create train andtest `Dataset` and `DataLoaders` with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from pathlib import Path\n",
    "# Setup path to the data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn our Image folder to datasets\n",
    "train_data_augment = datasets.ImageFolder(root=train_dir,\n",
    "                                          transform=train_transform_trivial,\n",
    "                                          )\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
    "                                        transform=test_transform_trivial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn datasets into DataLoaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 1 #os.cpu_count()\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_dataloader_augmented = DataLoader(dataset=train_data_augment,\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        num_workers=NUM_WORKERS)\n",
    "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 Create another model_1 and train it\n",
    "This time we will be using the same model class but with updated data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model_1 and send it to the target device\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = TinyVGG(input_shape=3,\n",
    "                  hidden_units=10,\n",
    "                  output_shape=len(train_data_augment.classes)).to(device)\n",
    "\n",
    "model_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create our loss function and an optimizer and call upon our `train()` function to train and evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "# setup loss and optimizer function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train the model 1\n",
    "model_1_results = train_loop(model=model_1,\n",
    "                        train_dataloader = train_dataloader_augmented,\n",
    "                        test_dataloader = test_dataloader_simple,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn= loss_fn,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        device=device)\n",
    "\n",
    "# End the timer and print out the time taken\n",
    "end_time = timer()\n",
    "print(f\"Total training time for model_1: {end_time-start_time:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.4 Plot loss curvers of  model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from typing import Dict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_1_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Comparing our model results\n",
    "Afetr evaluating oour models experiments on their own, its important to compare then to each other\n",
    "\n",
    "There's few different ways to do this:\n",
    "1. Hard Coding ( What we are doing)\n",
    "2. Pytorch + tensorboard\n",
    "3. Weights and Biases\n",
    "4. MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_0_df = pd.DataFrame(model_0_results)\n",
    "model_1_df = pd.DataFrame(model_1_results)\n",
    "model_0_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a plot\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(model_0_df))\n",
    "\n",
    "# plot the trainloss\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"Model 1\")\n",
    "plt.title(\"Train Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# plot the Test loss\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"Model 1\")\n",
    "plt.title(\"Test_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# plot the Train Accuracy\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"Model 1\")\n",
    "plt.title(\"Train Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# plot the Test Accuracy\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"Model 0\")\n",
    "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"Model 1\")\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Making a prediction on a custom image\n",
    "Although we have trained our model on custom data ..... how do you make a prediction on a sample thats not in train and also in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download custom image\n",
    "import requests\n",
    "\n",
    "# setup custom image path\n",
    "custom_image_path = data_path / \"steak.jpeg\"\n",
    "\n",
    "# Download the image if it doesn not exist\n",
    "if not custom_image_path.is_file():\n",
    "    with open(custom_image_path, 'wb') as f:\n",
    "        # When downloadign the image\n",
    "        request = requests.get(\"https://therecipecritic.com/wp-content/uploads/2019/05/besthomemadepizzahero.jpg\")\n",
    "        print(f\"Downloading..... {custom_image_path}\")\n",
    "        #print(request)\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"{custom_image_path} already exists, skipping downloading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_path = data_path / \"steak.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.1 Loading custom image with Pytorch\n",
    "we ahve to make our custom image is in the same format as the data our model was trained on.\n",
    "* In tensor form with datatype(torch.float32)\n",
    "* of shape 64x64x3\n",
    "* On the right Device\n",
    "We can read an image into Pytorch using: https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# read the custom image\n",
    "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(custom_image_uint8.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Custom image tensor:\\n {custom_image_uint8}\")\n",
    "print(f\"Custom image shape: {custom_image_uint8.shape}\")\n",
    "print(f\"Custom Image datatypes: {custom_image_uint8.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.2 Making predictions on a custom image with a trained pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error: Wrong image datatype\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    model_1(custom_image_uint8.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the custom image and convert to torch.float32\n",
    "custom_image = torchvision.io.read_image(path=str(custom_image_path)).type(torch.float32) / 255.\n",
    "custom_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(custom_image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error cause image not in correct size\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    model_1(custom_image.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a transform pipeline to resize the image\n",
    "custom_image_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64))\n",
    "])\n",
    "\n",
    "# Transfor the custom image\n",
    "custom_image_transformed = custom_image_transform(custom_image)\n",
    "\n",
    "# print out he shapes\n",
    "print(f\"Original image shape: {custom_image.shape}\")\n",
    "print(f\"Transformed Image shape: {custom_image_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(custom_image_transformed.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this error we forgot to add batch dimension to it\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    model_1(custom_image_transformed.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding an batch  dimension to the image\n",
    "custom_image_transformed.shape, custom_image_transformed.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    custom_image_pred = model_1(custom_image_transformed.unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_image_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : To make the predictions on a custom image we had to :\n",
    "* Load the image and turn it into a tensor\n",
    "* Make sure the image was on the same datatype as the model\n",
    "* Make sur ethe image was of the same shape as the data the mmodel was trained on \n",
    "* Make sure the image was on the same device as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logits -> prediction probabilities\n",
    "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
    "custom_image_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prediction probabilities -> predicted labels\n",
    "custom_image_pred_labels = torch.argmax(custom_image_pred_probs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augment.classes[custom_image_pred_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3 Putting custom image predictions together: building a function\n",
    "Ideal Outcome:\n",
    "* A function where we pass an image path to and have our model predict on that image\n",
    "and plot the image + prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def pred_and_plot_image(model: torch.nn.Module,\n",
    "                        image_path: str,\n",
    "                        class_names: List[str]=None,\n",
    "                        transform=None,\n",
    "                        device=device):\n",
    "    \"\"\"Makes a prediction on target image with a trained model and plots the image and prediction\"\"\"\n",
    "    # load the image\n",
    "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
    "\n",
    "    # Divide the image pixel values by 255 to get them between 0-1\n",
    "    target_image = target_image / 255.\n",
    "\n",
    "    # transform the data if necessary\n",
    "    if transform:\n",
    "        target_image = transform(target_image)\n",
    "\n",
    "    # Turn on eval model and make the prediction\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Add an extra dimension to the image ( this is the batch dimension)\n",
    "        target_image = target_image.unsqueeze(dim=0)\n",
    "\n",
    "        # Make a prediciton on the image with an extra dimension\n",
    "        target_image_pred = model(target_image.to(device))\n",
    "        \n",
    "    # Convert logits -> prediction probabilities\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # Convert the prediction proabbilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "\n",
    "    # Plot the image alongside the prediciton and prediciton probabilities\n",
    "    plt.imshow(target_image.squeeze().permute(1,2,0)) # remove the batch dimension and colour channel to last [H,W,C]\n",
    "    if class_names:\n",
    "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu(): .3f}\"\n",
    "    else:\n",
    "        title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu(): .3f}\"\n",
    "    plt.title(title)\n",
    "    plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup custom image path\n",
    "custom_image_path = data_path / \"steak.jpeg\"\n",
    "pred_and_plot_image(model=model_1,\n",
    "                    image_path=str(custom_image_path),\n",
    "                    class_names=train_data_augment.classes,\n",
    "                    transform=custom_image_transform,\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
